{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77db05f",
   "metadata": {},
   "source": [
    "### ä½ ç¾åœ¨åšçš„äº‹æƒ…ï¼Œå°±æ˜¯ä¸€å€‹å®Œæ•´çš„æœ¬åœ°ç«¯ç”Ÿæˆå¼ AI æ‡‰ç”¨ã€‚ä½ æ²’æœ‰ä½¿ç”¨ä»»ä½•é›²ç«¯æœå‹™ï¼Œæ‰€æœ‰é‹ç®—éƒ½åœ¨ä½ çš„é›»è…¦ä¸Šå®Œæˆã€‚é€™åœ¨é–‹ç™¼ AI æ‡‰ç”¨æ™‚æ˜¯å¾ˆå¸¸è¦‹çš„åšæ³•ï¼Œç‰¹åˆ¥æ˜¯ç‚ºäº†ä¿è­·è³‡æ–™éš±ç§ã€é™ä½æˆæœ¬æˆ–æ˜¯å®¢è£½åŒ–æ¨¡å‹è¡Œç‚ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0adf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è«‹æ±‚æˆåŠŸ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>å¤©ç©ºä¹‹æ‰€ä»¥æ˜¯è—è‰²ï¼Œæ˜¯ä¸€å€‹éå¸¸æœ‰è¶£ä¸”è¤‡é›œçš„ç¾è±¡ï¼Œä¸»è¦æ­¸åŠŸæ–¼ä¸€ç¨®å«åš<strong>ç‘åˆ©æ•£å°„ (Rayleigh scattering)</strong> çš„ç‰©ç†ç¾è±¡ã€‚ä»¥ä¸‹æ˜¯æ›´è©³ç´°çš„è§£é‡‹ï¼š</p>\n",
       "<p><strong>1. å¤ªé™½å…‰ç‚ºä»€éº¼æ˜¯ç™½è‰²çš„ï¼Ÿ</strong></p>\n",
       "<p>å¤ªé™½å…‰çœ‹èµ·ä¾†æ˜¯ç™½è‰²çš„ï¼Œä½†å¯¦éš›ä¸Šå®ƒæ˜¯ç”±ä¸åŒé¡è‰²çš„å…‰æ··åˆè€Œæˆã€‚å¤ªé™½å…‰æœ¬èº«åŒ…å«ç´…ã€æ©™ã€é»ƒã€ç¶ ã€è—ã€é›ã€ç´«ç­‰å„ç¨®é¡è‰²ã€‚</p>\n",
       "<p><strong>2. ç‘åˆ©æ•£å°„çš„åŸç†</strong></p>\n",
       "<ul>\n",
       "<li><strong>å…‰çš„æ³¢é•·ï¼š</strong> ä¸åŒçš„é¡è‰²å…‰å…·æœ‰ä¸åŒçš„æ³¢é•·ã€‚è—è‰²å’Œç´«è‰²çš„å…‰æ³¢é•·æ¯”è¼ƒçŸ­ï¼Œè€Œç´…è‰²çš„å…‰æ³¢é•·æ¯”è¼ƒé•·ã€‚</li>\n",
       "<li><strong>ç©ºæ°£ä¸­çš„å¾®ç²’ï¼š</strong> å¤§æ°£ä¸­å­˜åœ¨å¤§é‡çš„å¾®å°é¡†ç²’ï¼Œä¾‹å¦‚ç©ºæ°£ä¸­çš„æ°®æ°£å’Œæ°§æ°£ã€‚</li>\n",
       "<li><strong>ç‘åˆ©æ•£å°„ï¼š</strong> ç•¶å…‰ç·šç©¿éç©ºæ°£æ™‚ï¼Œæœƒç™¼ç”Ÿç‘åˆ©æ•£å°„ã€‚ç‘åˆ©æ•£å°„æ˜¯æŒ‡ç•¶å…‰ç·šé‡åˆ°å¾®å°ç²’å­æ™‚ï¼Œå…‰ç·šæœƒè¢«æ•£å°„åˆ°ä¸åŒæ–¹å‘çš„ï¼Œæ•£å°„çš„ç¨‹åº¦èˆ‡å…‰çš„æ³¢é•·æˆæ­£æ¯”ã€‚</li>\n",
       "<li><strong>è—å…‰æ•£å°„æ›´å²å®³ï¼š</strong> è—è‰²å’Œç´«è‰²çš„å…‰æ³¢é•·å¾ˆçŸ­ï¼Œæ‰€ä»¥å®ƒå€‘æ›´å®¹æ˜“è¢«ç©ºæ°£ä¸­çš„å¾®ç²’æ•£å°„ã€‚</li>\n",
       "</ul>\n",
       "<p><strong>3. ç‚ºä»€éº¼å¤©ç©ºæ˜¯è—è‰²ï¼Ÿ</strong></p>\n",
       "<p>ç”±æ–¼è—è‰²å…‰è¢«æ•£å°„åˆ°æ•´å€‹å¤©ç©ºï¼Œæ‰€ä»¥æˆ‘å€‘çœ‹åˆ°çš„å¤©ç©ºæ™‚ï¼Œæˆ‘å€‘çœ‹åˆ°çš„å°±æ˜¯è—è‰²å…‰ã€‚ å°±åƒé™½å…‰ç©¿éç©ºæ°£æ™‚ï¼Œè—è‰²å…‰æ›´å®¹æ˜“è¢«æ•£å°„ï¼Œæ‰€ä»¥æˆ‘å€‘çœ¼ç›æ›´å®¹æ˜“æ¥æ”¶åˆ°è—è‰²å…‰ã€‚</p>\n",
       "<p><strong>4. ç‚ºä»€éº¼æ—¥å‡ºå’Œæ—¥è½æ˜¯ç´…è‰²/æ©™è‰²ï¼Ÿ</strong></p>\n",
       "<p>ç•¶å¤ªé™½ä½æ–¼åœ°å¹³ç·šé™„è¿‘æ™‚ï¼Œå¤ªé™½å…‰éœ€è¦ç©¿éæ›´åšçš„å¤§æ°£å±¤æ‰èƒ½åˆ°é”æˆ‘å€‘çš„çœ¼ç›ã€‚åœ¨é€™å€‹éç¨‹ä¸­ï¼Œè—å…‰è¢«æ•£å°„å¾—éå¸¸å¤šï¼Œè€Œç´…å…‰å’Œé»ƒå…‰å¯ä»¥ç©¿é€æ›´é ï¼Œåˆ°é”æˆ‘å€‘çš„çœ¼ç›ã€‚å› æ­¤ï¼Œæˆ‘å€‘çœ‹åˆ°çš„å¤©ç©ºå‘ˆç¾ç´…è‰²æˆ–æ©™è‰²ã€‚</p>\n",
       "<p><strong>ç¸½çµï¼š</strong></p>\n",
       "<p>å¤©ç©ºå‘ˆç¾è—è‰²æ˜¯å› ç‚ºè—å…‰æ›´å®¹æ˜“è¢«ç©ºæ°£ä¸­çš„å¾®ç²’æ•£å°„ï¼Œè€Œç´…å…‰å’Œé»ƒå…‰å¯ä»¥ç©¿é€æ›´é ã€‚</p>\n",
       "<p>å¸Œæœ›é€™å€‹è§£é‡‹èƒ½è®“ä½ æ›´å¥½åœ°ç†è§£ç‚ºä»€éº¼å¤©ç©ºæ˜¯è—è‰²çš„ï¼</p>\n",
       "<hr />\n",
       "<p><strong>è£œå……èªªæ˜ï¼š</strong></p>\n",
       "<ul>\n",
       "<li><strong>æ²’æœ‰å…¶ä»–é¡è‰²ï¼š</strong>  å¤©ç©ºä¸¦ä¸æ˜¯å› ç‚ºåœ°çƒä¸Šå­˜åœ¨å…¶ä»–é¡è‰²ï¼Œè€Œæ˜¯å› ç‚ºæˆ‘å€‘åœ¨è§€æ¸¬æ™‚ï¼Œæˆ‘å€‘çœ¼ç›æ¥æ”¶åˆ°çš„å…‰ç·šæ˜¯è—è‰²ï¼Œè€Œå…¶ä»–é¡è‰²å…‰ç·šè¢«æ•£å°„äº†ã€‚</li>\n",
       "<li><strong>å…¶ä»–å› ç´ å½±éŸ¿ï¼š</strong>  é›–ç„¶ç‘åˆ©æ•£å°„æ˜¯ä¸»è¦åŸå› ï¼Œä½†å…¶ä»–å› ç´ ï¼Œä¾‹å¦‚å¤§æ°£ä¸­çš„é›²å±¤ï¼Œä¹Ÿæœƒå½±éŸ¿å¤©ç©ºçš„é¡è‰²ã€‚</li>\n",
       "</ul>\n",
       "<p>å¦‚æœä½ æƒ³äº†è§£æ›´å¤šé—œæ–¼å¤©ç©ºé¡è‰²çš„ç´°ç¯€ï¼Œå¯ä»¥é€²ä¸€æ­¥é–±è®€é—œæ–¼ç‘åˆ©æ•£å°„çš„ç§‘æ™®æ–‡ç« æˆ–å½±ç‰‡ã€‚</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#json ä¼æ¥­è·Ÿä¼æ¥­æºé€šçš„è³‡æ–™æ ¼å¼ æª”æ¡ˆå° æ•ˆèƒ½å¥½\n",
    "# https://github.com/ollama/ollama/blob/main/README.md#quickstart  æ¨¡å‹èªªæ˜æ›¸\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import markdown  # pip install markdown\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "\n",
    "data = {\n",
    "  \"model\": \"gemma3:1b\",\n",
    "  \"prompt\":\"ç‚ºä»€éº¼å¤©ç©ºæ˜¯è—è‰²?\",\n",
    "  \"stream\":False,\n",
    "  \"options\": { #åƒè€ƒèªªæ˜1\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print('è«‹æ±‚æˆåŠŸ')\n",
    "    #print('å›å‚³çš„json',response.json())\n",
    "    #print(type(response.json()))\n",
    "    \n",
    "    answer = response.json()['response']\n",
    "    #print(f\"AI å›ç­”:{answer}\")\n",
    "    markdown_answer = markdown.markdown(answer)\n",
    "\n",
    "    display(HTML(markdown_answer))\n",
    "\n",
    "else:\n",
    "    print('è«‹æ±‚å¤±æ•—')\n",
    "    print((f'ç‹€æ…‹ç¢¼:{ response.status_code}'))\n",
    "    print((f'éŒ¯èª¤è¨Šæ¯:{ response.text}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f23a371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ AI å›æ‡‰ï¼š\n",
      "{'error': \"model 'gpt-oss:20b' not found\"}\n",
      "No expected key found in response. Available keys: dict_keys(['error'])\n"
     ]
    }
   ],
   "source": [
    "#è€å¸«çš„ç¯„ä¾‹\n",
    "\n",
    "import requests\n",
    "\n",
    "def chat_with_ollama(prompt: str):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"gpt-oss:20b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": { #åƒè€ƒèªªæ˜1\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        }\n",
    "        \n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    result = response.json()\n",
    "    print(\"ğŸ’¬ AI å›æ‡‰ï¼š\")\n",
    "    # Print the whole result for debugging\n",
    "    print(result)\n",
    "    # Try to print the 'response' key if it exists, otherwise print possible keys\n",
    "    if \"response\" in result:\n",
    "        print(result[\"response\"])\n",
    "    elif \"message\" in result:\n",
    "        print(result[\"message\"])\n",
    "    elif \"content\" in result:\n",
    "        print(result[\"content\"])\n",
    "    else:\n",
    "        print(\"No expected key found in response. Available keys:\", result.keys())\n",
    "\n",
    "#ç¯„ä¾‹è¼¸å…¥\n",
    "chat_with_ollama(\"è«‹ç”¨ç°¡å–®çš„æ–¹å¼è§£é‡‹ä»€éº¼æ˜¯Pythonçš„å‡½å¼ï¼Ÿ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
